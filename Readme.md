# Pinecone Hybrid Search Demo

A demonstration of hybrid search implementation using Pinecone, combining dense semantic search with sparse keyword-based search (BM25) for improved retrieval accuracy.

## Overview

This project showcases how to implement hybrid search that leverages the strengths of two complementary search methods:
- **Dense Search (Semantic)**: Uses embedding models to understand meaning and context
- **Sparse Search (Keyword)**: Uses BM25 algorithm for exact term matching

## Why Hybrid Search?

Traditional search systems rely on either keyword matching or semantic understanding, but not both. Hybrid search combines these approaches:

- **Dense embeddings** capture semantic meaning (e.g., understanding "car" and "automobile" are similar)
- **Sparse BM25** excels at exact term matching (e.g., finding specific years, names, or technical terms)
- **Together**, they provide more robust and accurate search results than either method alone

## Features

- ‚ú® Hybrid search combining dense and sparse retrieval
- üîç BM25 encoder for keyword-based matching
- üß† Semantic embeddings for contextual understanding
- üìä Pinecone vector database integration
- üíæ Model persistence (save/load BM25 values)

## Prerequisites

- Python 3.8+
- Pinecone account and API key
- Required libraries: pinecone-client, pinecone-text, langchain, sentence-transformers

## Project Structure

```
.
‚îú‚îÄ‚îÄ hybrid_search_demo.ipynb    # Main demonstration notebook
‚îú‚îÄ‚îÄ bm25_values.json           # Saved BM25 encoder (optional)
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îî‚îÄ‚îÄ README.md                 # This file
```

## How It Works

### 1. Dense Vectors (Semantic Search)
Converts text into high-dimensional vectors using embedding models. This captures semantic meaning and context, allowing the system to find conceptually similar documents even when exact words don't match.

### 2. Sparse Vectors (Keyword Search)
Uses the BM25 algorithm, which scores documents based on term frequency, document length normalization, and inverse document frequency. This ensures exact keyword matches are properly weighted.

### 3. Hybrid Combination
Both scoring methods are combined to leverage their respective strengths. The system can find documents that are both semantically relevant and contain important exact matches.

## Key Concepts

### BM25 (Best Matching 25)
A probabilistic ranking function widely used in information retrieval. It improves upon simple TF-IDF by incorporating document length normalization and term saturation, making it more robust for real-world search applications.

### Dense Embeddings
Vector representations of text that capture semantic meaning. These are typically generated by neural network models trained on large text corpora to understand language context and relationships.

### Why Hybrid Outperforms Single-Method Search
- Dense search alone may miss documents with exact terminology that doesn't appear in training data
- Sparse search alone may miss semantically similar documents that use different vocabulary
- Hybrid search achieves higher precision and recall by considering both dimensions

## Example Results

**Query**: "French capital 2023"

The hybrid approach excels because:
- Dense vectors understand "French capital" relates to Paris
- Sparse vectors match "2023" exactly
- Combined scoring ensures the most relevant document ranks highest

## Common Use Cases

- üìö Document retrieval systems
- üîé Knowledge base search
- üí¨ Question-answering systems
- ü§ñ RAG (Retrieval-Augmented Generation) applications
- üì∞ News and article search
- üè¢ Enterprise search solutions

## Setup Notes

### Pinecone Configuration
You'll need to create a Pinecone index with dimensions matching your embedding model. The index should support hybrid search with both dense and sparse vectors.

### BM25 Model Persistence
The BM25 encoder can be trained on your corpus and saved for reuse. This is useful when deploying to production, as it ensures consistent vocabulary and scoring across sessions.

## Performance Considerations

- **Index size**: Hybrid search requires storing both dense and sparse vectors
- **Query latency**: Slightly higher than single-method search due to dual scoring
- **Accuracy gains**: Typically 10-30% improvement in retrieval metrics over single methods
- **Scalability**: Pinecone handles scaling transparently for both vector types

## Troubleshooting Tips

### Index Dimension Mismatch
Ensure your Pinecone index dimension matches your embedding model's output dimension.

### BM25 Encoder Fitting
The encoder needs vocabulary statistics from your corpus. This happens automatically when adding documents, or can be done explicitly for better control.

### Empty Results
Check that documents have been properly indexed with both dense and sparse vectors, and verify your Pinecone connection.

## Future Enhancements

- Add evaluation metrics (precision, recall, nDCG)
- Implement custom weighting between dense and sparse scores
- Add support for metadata filtering
- Include reranking for top-k results

## References

- [Pinecone Documentation](https://docs.pinecone.io/)
- [BM25 Algorithm](https://en.wikipedia.org/wiki/Okapi_BM25)
- [LangChain Retrievers](https://python.langchain.com/docs/modules/data_connection/retrievers/)


## Acknowledgments

Built with Pinecone for vector database, LangChain for retrieval abstractions, and pinecone-text for BM25 implementation.